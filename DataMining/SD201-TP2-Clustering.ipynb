{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering with scikit-learn\n",
    "\n",
    "We are going to use the implementation for k-means from scikit-learn, see [here](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit) for a documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using k-means from scikit-learn, we recommend you that your data be stored as a numpy array. Create it or convert your data into a numpy array as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#create a numpy array\n",
    "X = np.array([[1, 2], [1, 4], [1, 0],[4, 2], [4, 4], [4, 0]])\n",
    "\n",
    "#convert a list to a numpy array\n",
    "a=[]\n",
    "for i in range(0,10):\n",
    "    p=[i,2*i]\n",
    "    a.append(p)\n",
    "\n",
    "Y=np.array(a, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following execute the k-means algorithm on the points in X. Make sure you understand the parameters see [here](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init='random', n_clusters=2, max_iter=10000, n_init=100).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gives the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code computes the clusters for the points [0,0] and [4,4]. In this case, [0,0] is placed in cluster labeled 0 and [4,4] in the cluster labeled 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict([[4,4],[0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the centroids (in this case called centers ) of the two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [4., 2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run Algo with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#read the input csv file\n",
    "df=pd.read_csv('SD201-TP2-Clustering-data.csv')\n",
    "\n",
    "Z=[]\n",
    "for val in df.values:\n",
    "    Z.append(val[1:])\n",
    "Z=np.array(Z, dtype='float32')\n",
    "\n",
    "#use default KMeans values (don't specify anything to use defaults)\n",
    "kmeans = KMeans(init='random').fit(Z) #init='random', n_clusters=8, max_iter=300, n_init=10 (these are the default values)\n",
    "labels = kmeans.labels_\n",
    "stocks = df.T.values[0]\n",
    "clusters = [[]]*8\n",
    "i=0\n",
    "for label in labels:\n",
    "    clusters[label] = clusters[label] + [stocks[i]]\n",
    "    i+=1\n",
    "\n",
    "\n",
    "SSE = kmeans.inertia_\n",
    "\n",
    "# calculating the SSE manually:\n",
    "i=0;mySSE=0\n",
    "centers = kmeans.cluster_centers_\n",
    "for value in Z:\n",
    "    mySSE += sum(np.power(value-centers[labels[i]],2))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hewlett-Packard'],\n",
       " ['American Express',\n",
       "  'Boeing',\n",
       "  'IBM',\n",
       "  'The Home Depot',\n",
       "  'Walt Disney',\n",
       "  'Intel',\n",
       "  'Wal-Mart',\n",
       "  'General Electric',\n",
       "  'United Technologies',\n",
       "  'Travelers',\n",
       "  'JPMorgan Chase',\n",
       "  '3M',\n",
       "  'Johnson & Johnson'],\n",
       " ['Cisco Systems', 'Microsoft', 'Alcoa'],\n",
       " ['Verizon', 'Merck'],\n",
       " ['Chevron', 'Pfizer', 'ExxonMobil'],\n",
       " ['Bank of America'],\n",
       " ['DuPont', 'Caterpillar'],\n",
       " ['Kraft', 'Procter & Gamble', 'AT&T', 'McDonalds', 'Coca-Cola']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648.9618647838797, 1648.9619140625)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySSE, SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the K-Means algorithm with its default values, initiating with random centroids, limiting the max_iter to 300, initiating it with 10 different centroids to take the best result, setting a tolerance of 1e-4 in order with the centroid and of course being in compliance with the 8-cluster rule.\n",
    "I also wrote my SSE calculation snippet which converges to the same value as kmeans.inertia_\n",
    "\n",
    "We get an SSE in the neighbourhood of 1700.\n",
    "Looking deeper in this number, it means that the average scalar squared distance in the 25-dimensional space (study on 25 different dates) is 1700/30= 56.6667 (unit^2)\n",
    "\n",
    "We devide by 30 since we are clustering 30 different points (companies) in the 25D space, so the average distance is 7.5 (unit) between each company's stock and its chosen centroid of cluster. The unit is the direct distance between 2 points in a 25D space.\n",
    "\n",
    "We got these results using the default K-Means algorithm with random initiation, which explains the results that change with each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Improving the K-Means Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE 1540.729736328125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['American Express', 'Bank of America', 'JPMorgan Chase'],\n",
       " ['Kraft',\n",
       "  'Verizon',\n",
       "  'IBM',\n",
       "  'The Home Depot',\n",
       "  'Procter & Gamble',\n",
       "  'Wal-Mart',\n",
       "  'AT&T',\n",
       "  'Merck',\n",
       "  'Travelers',\n",
       "  'McDonalds',\n",
       "  'Coca-Cola'],\n",
       " ['Chevron', 'Pfizer', 'ExxonMobil'],\n",
       " ['Hewlett-Packard'],\n",
       " ['Cisco Systems'],\n",
       " ['DuPont', 'Caterpillar'],\n",
       " ['Boeing',\n",
       "  'Microsoft',\n",
       "  'Walt Disney',\n",
       "  'Intel',\n",
       "  'General Electric',\n",
       "  'United Technologies',\n",
       "  '3M',\n",
       "  'Johnson & Johnson'],\n",
       " ['Alcoa']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=8,  max_iter=100000, n_init=100, tol = 1e-10).fit(Z) \n",
    "labels = kmeans.labels_\n",
    "stocks = df.T.values[0]\n",
    "clusters = [[]]*8\n",
    "i=0\n",
    "for label in labels:\n",
    "    clusters[label] = clusters[label] + [stocks[i]]\n",
    "    i+=1\n",
    "SSE = kmeans.inertia_\n",
    "print(\"SSE\",SSE)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decrease the SSE, we need to improve the K-Means algorithm, from initiation, the number of maximum iterations, the number of repeated calculations to the tolerance (epsilon).\n",
    "\n",
    "As a first step, we need to use the K-Means++ as an initiation algorithm to guaguarantee our convergence and accelerating the calculation time. This will definitely always decrease the total SSE at convergence since it begins the kmeans algorithm from an optimized starting point.\n",
    "Just by changing this parameter, we get an average SSE of 1600 (a decrease of 100) which is an improved SSE compared to the initial default result.\n",
    "\n",
    "As a second step, we can play on the [max_iter] <-> [tolerance] parameters.\n",
    "In fact these two parameters are the two conditionals that break the algorithm proceding, or declare its convergence (OR relation).\n",
    "Increasing the max number of iterations in a test should decrease the SSE since it is guarantteed to get smaller or equal SSE in each next step. This alteration always improves the SSE (decrease), unless the centroids converge quickly (optimized centroids). In such a case we won't attend the max_iter limit, but stop on tolerance.\n",
    "Increasing the max_iter, we get an improved SSE in the region of 1500, which is also a great improvement.\n",
    "\n",
    "\n",
    "Note:\n",
    "n_init is an important parameter that simulates the repetition of the algorithm for n_init times and returning us the best realisation. But, increasing it never guarantees us a better SSE (decreased) since it is a random process that only relies on the random choice of the initial centroid!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Labeling Clusters with Appropriate Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copy the distribution that we have got with an SSE of 1540.73 to label its clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Banking\n",
      "['American Express', 'Bank of America', 'JPMorgan Chase']\n",
      "\n",
      "2 : Consumer goods\n",
      "['Kraft', 'Verizon', 'IBM', 'The Home Depot', 'Procter & Gamble', 'Wal-Mart', 'AT&T', 'Merck', 'Travelers', 'McDonalds', 'Coca-Cola']\n",
      "\n",
      "3 : Oil\n",
      "['Chevron', 'Pfizer', 'ExxonMobil']\n",
      "\n",
      "4 : Computers\n",
      "['Hewlett-Packard']\n",
      "\n",
      "5 : Networking\n",
      "['Cisco Systems']\n",
      "\n",
      "6 : NO CLASS\n",
      "['DuPont', 'Caterpillar']\n",
      "\n",
      "7 : Manufacturers\n",
      "['Boeing', 'Microsoft', 'Walt Disney', 'Intel', 'General Electric', 'United Technologies', '3M', 'Johnson & Johnson']\n",
      "\n",
      "8 : Aluminum(Industry)\n",
      "['Alcoa']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultCluster= [['American Express', 'Bank of America', 'JPMorgan Chase'],\n",
    " ['Kraft',\n",
    "  'Verizon',\n",
    "  'IBM',\n",
    "  'The Home Depot',\n",
    "  'Procter & Gamble',\n",
    "  'Wal-Mart',\n",
    "  'AT&T',\n",
    "  'Merck',\n",
    "  'Travelers',\n",
    "  'McDonalds',\n",
    "  'Coca-Cola'],\n",
    " ['Chevron', 'Pfizer', 'ExxonMobil'],\n",
    " ['Hewlett-Packard'],\n",
    " ['Cisco Systems'],\n",
    " ['DuPont', 'Caterpillar'],\n",
    " ['Boeing',\n",
    "  'Microsoft',\n",
    "  'Walt Disney',\n",
    "  'Intel',\n",
    "  'General Electric',\n",
    "  'United Technologies',\n",
    "  '3M',\n",
    "  'Johnson & Johnson'],\n",
    " ['Alcoa']]\n",
    "\n",
    "labels = ['Banking', 'Consumer goods', 'Oil', 'Computers', 'Networking', 'NO CLASS', 'Manufacturers', 'Aluminum(Industry)']\n",
    "\n",
    "result = dict(zip(labels,resultCluster))\n",
    "i=1\n",
    "for r in result:\n",
    "    print(i,\":\",end=\" \")\n",
    "    print(r)\n",
    "    print(result[r])\n",
    "    print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation:\n",
    "\n",
    "    The clusters 1, 4, 5, and 8 are perfect matches.\n",
    "    Cluster 3 is almost perfect since it contains two oil companies but is broken by a chemicals and health care company.\n",
    "    Cluster 2 is mostly made of companies that sell goods directly to the consumers like McDonald's, Coca-Cola, Kraft, Procter&Gamble, Walmart... However Home Depot, IBM, Verizon, and AT&T are communications and electronics stocks, Merck is for health care, and Travelers is an insurance company. But overall, this cluster fits under Consumer goods.\n",
    "    Cluster 7 has big industry manufacturers such as Boeing, General Electric, United Technologies, 3M, Johnson & Johnson, Intel, and Microsoft. Walt Disney is for entertainment.\n",
    "    So Manufacturers stocks fits well this cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
